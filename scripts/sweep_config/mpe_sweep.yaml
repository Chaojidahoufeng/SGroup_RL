program: train_mpe.py
project: sweep_MPE
name: simple_spread
command:
  - ${env}
  - python3
  - ${program}
  - --recurrent_policy
  - ${args}
early_terminate:
  type: hyperband
  s: 2
  eta: 3
  max_iter: 27
method: grid
metric:
  goal: maximize
  name: average_episode_rewards
parameters:
  algorithm_name:
    distribution: constant
    value: "check_sweep"
  data_chunk_length:
    distribution: constant
    value: 10
  env_name:
    distribution: constant
    value: "MPE"
  episode_length:
    distribution: constant
    value: 25
  lr:
    distribution: categorical
    values: [0.01, 0.001, 0.0001]
  ppo_epoch:
    distribution: categorical
    values: [5, 15, 20]
  num_agents:
    distribution: constant
    value: 3
  num_env_steps:
    distribution: constant
    value: 100000
  num_landmarks:
    distribution: constant
    value: 3
  scenario_name:
    distribution: constant
    value: "simple_spread"
  seed:
    distribution: constant
    value: 1
  num_mini_batch:
    distribution: constant
    value: 1
  n_rollout_threads:
    distribution: constant
    value: 20
  gain:
    distribution: constant
    value: 0.01

